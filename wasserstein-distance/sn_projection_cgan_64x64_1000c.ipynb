{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral normalization GAN with categorical projection conditioning\n",
    "*Thomas Viehmann <tv@lernapparat.de>*\n",
    "\n",
    "# This is work in progress, i.e. it probably doesn't work\n",
    "\n",
    "Spectral Normalization GANs are an exiting new regularization method that approximates the Wasserstein loss as a discriminator function. The authors also demonstrated the capabilities of a projection method for the discriminator - generating images for all 1000 imagenet (LSVRC2012) categories. We implement the smaller 64x64 pixel variant.\n",
    "One of the crucial ingredients on the side of the Generator is a Conditional Batch Norm that enables learning a class-specific multiplier and bias.\n",
    "\n",
    "This repository\n",
    "- is a straightforward adaptation of the [official chainer-based implementation in the 64x64 case](https://github.com/pfnet-research/sngan_projection)\n",
    "- PyTorch's [spectral_norm](https://pytorch.org/docs/master/nn.html#torch.nn.utils.spectral_norm) implementation\n",
    "- a custom Conditional Batch Norm modelled after the above official implementation but in a PyTorch-style way (see below)\n",
    "- Python 3 and PyTorch / master + [PR 9020](https://github.com/pytorch/pytorch/pull/9020)\n",
    "\n",
    "First let's import something:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from matplotlib import pyplot\n",
    "import torchvision\n",
    "import os\n",
    "%matplotlib notebook\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Batch Norm\n",
    "\n",
    "Here is the promised conditional batch norm. It aims to be compatible in functionality [to the SN-GAN author's version](https://github.com/pfnet-research/sngan_projection), the original reference seems to be [de Vries et. al., Modulating early visual processing by language](https://arxiv.org/abs/1707.00683).\n",
    "\n",
    "It works pretty much like [regular batch norm](https://pytorch.org/docs/master/nn.html#torch.nn.BatchNorm2d) *except* that it has a per-class weight $\\gamma$ and bias $\\beta$.\n",
    "In particular, note that the input mean and variance (to be \"cleaned\") and the running statistics are *not* class dependent. (Of course, one might wonder whether it should, but that is for another day...)\n",
    "\n",
    "There also is a conditional instance norm, (which would resolve the input that the statistics being generated accross classes during training, but not during evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalConditionalBatchNorm(torch.nn.Module):\n",
    "    # as in the chainer SN-GAN implementation , we keep per-cat XXX.\n",
    "    # I should care more about accreal\n",
    "    def __init__(self, num_features, num_cats, eps=1e-5, momentum=0.1, affine=True,\n",
    "                 track_running_stats=True):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.num_cats = num_cats\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.affine = affine\n",
    "        self.track_running_stats = track_running_stats\n",
    "        if self.affine:\n",
    "            self.weight = torch.nn.Parameter(torch.Tensor(num_cats, num_features))\n",
    "            self.bias = torch.nn.Parameter(torch.Tensor(num_cats, num_features))\n",
    "        else:\n",
    "            self.rsegister_parameter('weight', None)\n",
    "            self.register_parameter('bias', None)\n",
    "        if self.track_running_stats:\n",
    "            self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "            self.register_buffer('running_var', torch.ones(num_features))\n",
    "            self.register_buffer('num_batches_tracked', torch.tensor(0, dtype=torch.long))\n",
    "        else:\n",
    "            self.register_parameter('running_mean', None)\n",
    "            self.register_parameter('running_var', None)\n",
    "            self.register_parameter('num_batches_tracked', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_running_stats(self):\n",
    "        if self.track_running_stats:\n",
    "            self.running_mean.zero_()\n",
    "            self.running_var.fill_(1)\n",
    "            self.num_batches_tracked.zero_()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.reset_running_stats()\n",
    "        if self.affine:\n",
    "            self.weight.data.uniform_()\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "    def _check_input_dim(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, input, cats):\n",
    "        #self._check_input_dim(input)\n",
    "\n",
    "        exponential_average_factor = 0.0\n",
    "\n",
    "        if self.training and self.track_running_stats:\n",
    "            self.num_batches_tracked += 1\n",
    "            if self.momentum is None:  # use cumulative moving average\n",
    "                exponential_average_factor = 1.0 / self.num_batches_tracked.item()\n",
    "            else:  # use exponential moving average\n",
    "                exponential_average_factor = self.momentum\n",
    "\n",
    "        n = input.size(0)\n",
    "        numel_per_feature = input.numel()/input.size(1)\n",
    "        if self.training or not self.track_running_stats:\n",
    "            with torch.no_grad():\n",
    "                m = input\n",
    "                for d in range(input.dim()):\n",
    "                    if d != 1:\n",
    "                        m = m.mean(d, keepdim=True)\n",
    "                v = (input-m).pow_(2)\n",
    "                for d in range(input.dim()):\n",
    "                    if d != 1:\n",
    "                        v = v.mean(d, keepdim=True)\n",
    "                unbiased_var_update = (v * (numel_per_feature / (numel_per_feature - 1.0))).squeeze_().mul_(exponential_average_factor)\n",
    "\n",
    "                if self.track_running_stats:\n",
    "                    self.running_var *= (1 - exponential_average_factor)\n",
    "                    self.running_var += unbiased_var_update\n",
    "                    self.running_mean *= (1 - exponential_average_factor)\n",
    "                    self.running_mean += exponential_average_factor * m.squeeze()\n",
    "        else:\n",
    "            shape = [1, -1] + (input.dim() - 2) * [1]\n",
    "            v = self.running_var.detach().view(shape)\n",
    "            m = self.running_mean.detach().view(shape)\n",
    "            \n",
    "\n",
    "        x = (input - m) / (v + self.eps).sqrt_()\n",
    "        \n",
    "        if self.affine:\n",
    "            shape = [n, -1] + (input.dim() - 2) * [1]\n",
    "            weight = self.weight.index_select(0, cats).view(shape)\n",
    "            bias = self.bias.index_select(0, cats).view(shape)\n",
    "            x = x * weight + bias\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return '{num_features}, num_cats={num_cats}, eps={eps}, momentum={momentum}, affine={affine}, ' \\\n",
    "               'track_running_stats={track_running_stats}'.format(**self.__dict__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "\n",
    "With that, we can define the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResGenBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels=None, ksize=3, pad=1,\n",
    "                 activation=torch.nn.functional.relu, upsample=False, n_classes=0):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.upsample = upsample\n",
    "        self.learnable_sc = in_channels != out_channels or upsample\n",
    "        hidden_channels = out_channels if hidden_channels is None else hidden_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.c1 = torch.nn.Conv2d(in_channels, hidden_channels, ksize, padding=pad)\n",
    "        torch.nn.init.xavier_uniform_(self.c1.weight, gain=(2**0.5))\n",
    "        torch.nn.init.zeros_(self.c1.bias)\n",
    "        self.c2 = torch.nn.Conv2d(hidden_channels, out_channels, ksize, padding=pad)\n",
    "        torch.nn.init.xavier_uniform_(self.c2.weight, gain=(2**0.5))\n",
    "        torch.nn.init.zeros_(self.c2.bias)\n",
    "        if n_classes > 0:\n",
    "            self.b1 = CategoricalConditionalBatchNorm(in_channels, n_classes)\n",
    "            self.b2 = CategoricalConditionalBatchNorm(hidden_channels, n_classes)\n",
    "        else:\n",
    "            self.b1 = torch.nn.BatchNorm2d(in_channels)\n",
    "            self.b2 = torch.nn.BatchNorm2d(hidden_channels)\n",
    "        if self.learnable_sc:\n",
    "            self.c_sc = torch.nn.Conv2d(in_channels, out_channels, 1, padding=0)\n",
    "            torch.nn.init.xavier_uniform_(self.c_sc.weight)\n",
    "            torch.nn.init.zeros_(self.c_sc.bias)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        h = x\n",
    "        h = self.b1(h, y) if y is not None else self.b1(h)\n",
    "        h = self.activation(h)\n",
    "        if self.upsample:\n",
    "            h = torch.nn.functional.upsample(h, scale_factor=2)\n",
    "        h = self.c1(h)\n",
    "        h = self.b2(h, y) if y is not None else self.b2(h)\n",
    "        h = self.activation(h)\n",
    "        h = self.c2(h)\n",
    "        if self.learnable_sc:\n",
    "            if self.upsample:\n",
    "                x = torch.nn.functional.upsample(x, scale_factor=2)\n",
    "            sc = self.c_sc(x)\n",
    "        else:\n",
    "            sc = x\n",
    "        return h + sc\n",
    "\n",
    "\n",
    "class ResNetGenerator(torch.nn.Module):\n",
    "    def __init__(self, ch=64, dim_z=128, bottom_width=4, activation=torch.nn.functional.relu, n_classes=0, distribution=\"normal\"):\n",
    "        super().__init__()\n",
    "        self.bottom_width = bottom_width\n",
    "        self.activation = activation\n",
    "        self.distribution = distribution\n",
    "        self.dim_z = dim_z\n",
    "        self.n_classes = n_classes\n",
    "        self.l1 = torch.nn.Linear(dim_z, (bottom_width ** 2) * ch * 16)\n",
    "        torch.nn.init.xavier_uniform_(self.l1.weight)\n",
    "        torch.nn.init.zeros_(self.l1.bias)\n",
    "        self.block2 = ResGenBlock(ch * 16, ch * 8, activation=activation, upsample=True, n_classes=n_classes)\n",
    "        self.block3 = ResGenBlock(ch * 8, ch * 4, activation=activation, upsample=True, n_classes=n_classes)\n",
    "        self.block4 = ResGenBlock(ch * 4, ch * 2, activation=activation, upsample=True, n_classes=n_classes)\n",
    "        self.block5 = ResGenBlock(ch * 2, ch, activation=activation, upsample=True, n_classes=n_classes)\n",
    "        self.b6 = torch.nn.BatchNorm2d(ch)\n",
    "        self.l6 = torch.nn.Conv2d(ch, 3, 3, stride=1, padding=1)\n",
    "        torch.nn.init.xavier_uniform_(self.l6.weight)\n",
    "        torch.nn.init.zeros_(self.l6.bias)\n",
    "\n",
    "    def forward(self, batchsize=64, z=None, y=None):\n",
    "        anyparam = next(self.parameters())\n",
    "        if z is None:\n",
    "            z = torch.randn(batchsize, self.dim_z, dtype=anyparam.dtype, device=anyparam.device)\n",
    "        if y is None and self.n_classes > 0:\n",
    "            y = torch.randint(0, self.n_classes, (batchsize,), device=anyparam.device, dtype=torch.long)\n",
    "        if (y is not None) and z.shape[0] != y.shape[0]:\n",
    "            raise Exception('z.shape[0] != y.shape[0], z.shape[0]={}, y.shape[0]={}'.format(z.shape[0], y.shape[0]))\n",
    "        h = z\n",
    "        h = self.l1(h)\n",
    "        h = h.reshape(h.shape[0], -1, self.bottom_width, self.bottom_width)\n",
    "        h = self.block2(h, y)\n",
    "        h = self.block3(h, y)\n",
    "        h = self.block4(h, y)\n",
    "        h = self.block5(h, y)\n",
    "        h = self.b6(h)\n",
    "        h = self.activation(h)\n",
    "        h = torch.tanh(self.l6(h))\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "\n",
    "And the discriminator. So one of the subtle differences between ResDisBlock and the ResDisOptimizedBlock is that ResDisBlock starts with an activation - even though these look like they could be both covered by a single module..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResDisBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels=None, ksize=3, pad=1,\n",
    "                 activation=torch.nn.functional.relu, downsample=False):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.downsample = downsample\n",
    "        self.learnable_sc = (in_channels != out_channels) or downsample\n",
    "        hidden_channels = in_channels if hidden_channels is None else hidden_channels\n",
    "        self.c1 = torch.nn.Conv2d(in_channels, hidden_channels, ksize, padding=pad)\n",
    "        torch.nn.init.xavier_uniform_(self.c1.weight, gain=(2**0.5))\n",
    "        torch.nn.init.zeros_(self.c1.bias)\n",
    "        torch.nn.utils.spectral_norm(self.c1)\n",
    "        self.c2 = torch.nn.Conv2d(hidden_channels, out_channels, ksize, padding=pad)\n",
    "        torch.nn.init.xavier_uniform_(self.c2.weight, gain=(2**0.5))\n",
    "        torch.nn.init.zeros_(self.c2.bias)\n",
    "        torch.nn.utils.spectral_norm(self.c2)\n",
    "        if self.learnable_sc:\n",
    "            self.c_sc = torch.nn.Conv2d(in_channels, out_channels, 1, padding=0)\n",
    "            torch.nn.init.xavier_uniform_(self.c_sc.weight)\n",
    "            torch.nn.init.zeros_(self.c_sc.bias)\n",
    "            torch.nn.utils.spectral_norm(self.c_sc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = self.activation(h)\n",
    "        h = self.c1(h)\n",
    "        h = self.activation(h)\n",
    "        h = self.c2(h)\n",
    "        if self.downsample:\n",
    "            h = torch.nn.functional.avg_pool2d(h, 2)\n",
    "        if self.learnable_sc:\n",
    "            sc = self.c_sc(x)\n",
    "            if self.downsample:\n",
    "                sc = torch.nn.functional.avg_pool2d(sc, 2)\n",
    "        else:\n",
    "            sc = x\n",
    "        return h + sc\n",
    "\n",
    "class ResDisOptimizedBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, ksize=3, pad=1, activation=torch.nn.functional.relu):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.c1 = torch.nn.Conv2d(in_channels, out_channels, ksize, padding=pad)\n",
    "        torch.nn.init.xavier_uniform_(self.c1.weight, gain=(2**0.5))\n",
    "        torch.nn.init.zeros_(self.c1.bias)\n",
    "        torch.nn.utils.spectral_norm(self.c1)\n",
    "        self.c2 = torch.nn.Conv2d(out_channels, out_channels, ksize, padding=pad)\n",
    "        torch.nn.init.xavier_uniform_(self.c2.weight, gain=(2**0.5))\n",
    "        torch.nn.init.zeros_(self.c2.bias)\n",
    "        torch.nn.utils.spectral_norm(self.c2)\n",
    "        self.c_sc = torch.nn.Conv2d(in_channels, out_channels, 1, padding=0)\n",
    "        torch.nn.init.xavier_uniform_(self.c_sc.weight)\n",
    "        torch.nn.init.zeros_(self.c_sc.bias)\n",
    "        torch.nn.utils.spectral_norm(self.c_sc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = self.c1(h)\n",
    "        h = self.activation(h)\n",
    "        h = self.c2(h)\n",
    "        h = torch.nn.functional.avg_pool2d(h, 2)\n",
    "        sc = self.c_sc(x)\n",
    "        sc = torch.nn.functional.avg_pool2d(sc, 2)\n",
    "        return h + sc\n",
    "\n",
    "class SNResNetProjectionDiscriminator(torch.nn.Module):\n",
    "    def __init__(self, ch=64, n_classes=0, activation=torch.nn.functional.relu):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.block1 = ResDisOptimizedBlock(3, ch)\n",
    "        self.block2 = ResDisBlock(ch, ch * 2, activation=activation, downsample=True)\n",
    "        self.block3 = ResDisBlock(ch * 2, ch * 4, activation=activation, downsample=True)\n",
    "        self.block4 = ResDisBlock(ch * 4, ch * 8, activation=activation, downsample=True)\n",
    "        self.block5 = ResDisBlock(ch * 8, ch * 16, activation=activation, downsample=True)\n",
    "        self.l6 = torch.nn.Linear(ch * 16, 1)\n",
    "        torch.nn.init.xavier_uniform_(self.l6.weight)\n",
    "        torch.nn.init.zeros_(self.l6.bias)\n",
    "\n",
    "\n",
    "        if n_classes > 0:\n",
    "            self.l_y = torch.nn.Embedding(n_classes, ch * 16)\n",
    "            torch.nn.init.xavier_uniform_(self.l6.weight)\n",
    "            torch.nn.init.zeros_(self.l6.bias)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        h = x\n",
    "        h = self.block1(h)\n",
    "        h = self.block2(h)\n",
    "        h = self.block3(h)\n",
    "        h = self.block4(h)\n",
    "        h = self.block5(h)\n",
    "        h = self.activation(h)\n",
    "        h = h.sum([2, 3])\n",
    "        output = self.l6(h)\n",
    "        if y is not None:\n",
    "            w_y = self.l_y(y)\n",
    "            output += (w_y * h).sum(dim=1, keepdim=True)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it together\n",
    "\n",
    "Let's have a Hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e9e68f308c4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0minit_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0002\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnum_discriminator_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "batchsize = 64\n",
    "num_iterations = 250000\n",
    "iterations_decay_start = 200000\n",
    "seed = 0\n",
    "display_interval = 100\n",
    "snapshot_interval = 10000\n",
    "evaluation_interval = 5000\n",
    "init_lr = 0.0002\n",
    "num_discriminator_iter = 5\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "\n",
    "We use the imagenet dataloader from `torchvision`. We resize to 64x64. (I'm not sure whether the original implementation does some cropping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/home/datasets/imagenet/'\n",
    "traindir = os.path.join(DATADIR, 'train')\n",
    "valdir = os.path.join(DATADIR, 'val')\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "        traindir,\n",
    "        torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize((64,64)),\n",
    "            #torchvision.transforms.RandomResizedCrop(224),\n",
    "            #torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            #normalize\n",
    "        ]))\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(\n",
    "        valdir,\n",
    "        torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize((64,64)),\n",
    "            #torchvision.transforms.Resize(256),\n",
    "            #torchvision.transforms.CenterCrop(224),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            #normalize\n",
    "        ]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNResNetProjectionDiscriminator(\n",
       "  (block1): ResDisOptimizedBlock(\n",
       "    (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c_sc): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (block2): ResDisBlock(\n",
       "    (c1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c_sc): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (block3): ResDisBlock(\n",
       "    (c1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c_sc): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (block4): ResDisBlock(\n",
       "    (c1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c_sc): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (block5): ResDisBlock(\n",
       "    (c1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c2): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c_sc): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (l6): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (l_y): Embedding(1000, 1024)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = ResNetGenerator(dim_z=128, bottom_width=4, ch=64, n_classes=1000)\n",
    "discriminator = SNResNetProjectionDiscriminator(ch=64, n_classes=1000)\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def endless_train_dl(dl):\n",
    "    while True:\n",
    "        for b in dl:\n",
    "            yield b\n",
    "\n",
    "opt_dis = torch.optim.Adam(params=discriminator.parameters(), lr=init_lr, betas=(0.0, 0.9))\n",
    "opt_gen = torch.optim.Adam(params=generator.parameters(), lr=init_lr, betas=(0.0, 0.9))\n",
    "train_dl_ = torch.utils.data.DataLoader(train_dataset, batch_size=batchsize, shuffle=True, pin_memory=True, num_workers=4)\n",
    "train_dl = endless_train_dl(train_dl_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chicken!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb1e98a7a58>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb25401f048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IPython.terminal.pt_inputhooks.backends%matplotlib inline\n",
    "im, lab = train_dataset[11000]\n",
    "im = im.permute(1,2,0).numpy()\n",
    "im = im - im.min()\n",
    "im = im / im.max()\n",
    "pyplot.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Training promises to take 60 hours on my computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for it_nr in range(num_iterations):\n",
    "    opt_dis.param_groups[0]['lr'] = init_lr * 1 - max(it_nr - iterations_decay_start, 0) / (num_iterations - iterations_decay_start)\n",
    "    opt_gen.param_groups[0]['lr'] = init_lr * 1 - max(it_nr - iterations_decay_start, 0) / (num_iterations - iterations_decay_start)\n",
    "    time1 = time.time()\n",
    "    for i in range(num_discriminator_iter):\n",
    "        if i == 0:\n",
    "            discriminator.eval() # ?\n",
    "            for p in discriminator.parameters():\n",
    "                p.requires_grad = False\n",
    "            generator.train()\n",
    "            for p in generator.parameters():\n",
    "                p.requires_grad = True\n",
    "            # generator step batch size could be made different from batch size\n",
    "            y_fake = torch.randint(0, generator.n_classes, (batchsize,), device=device, dtype=torch.long)\n",
    "            x_fake = generator(batchsize, y=y_fake)\n",
    "            dis_fake = discriminator(x_fake, y=y_fake)\n",
    "            loss_gen = -dis_fake.mean()\n",
    "            opt_gen.zero_grad()\n",
    "            loss_gen.backward()\n",
    "            opt_gen.step()\n",
    "\n",
    "        discriminator.train() # ?\n",
    "        for p in discriminator.parameters():\n",
    "            p.requires_grad = True\n",
    "        generator.eval()\n",
    "        for p in generator.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        x_real, y_real = next(train_dl)\n",
    "        x_real = x_real.to(device)\n",
    "        y_real = y_real.to(device)\n",
    "        bs = len(x_real)\n",
    "        dis_real = discriminator(x_real, y=y_real)\n",
    "        with torch.no_grad():\n",
    "            y_fake = torch.randint(0, generator.n_classes, (bs,), device=device, dtype=torch.long)\n",
    "            x_fake = generator(bs, y=y_fake).detach()\n",
    "        dis_fake = discriminator(x_fake, y=y_fake)\n",
    "\n",
    "        loss_dis = (torch.nn.functional.relu(1. - dis_real).mean() +\n",
    "                    torch.nn.functional.relu(1. + dis_fake).mean())\n",
    "        opt_dis.zero_grad()\n",
    "        loss_dis.backward()\n",
    "        opt_dis.step()\n",
    "    print('loss_gen', loss_gen.item())\n",
    "    print('it_nr',it_nr, 'i', i, 'loss_dis', loss_dis.item())\n",
    "    time2 = time.time()\n",
    "    print (\"it_nr\", it_nr, \"/\", num_iterations, time2 - time1)\n",
    "    remaining = int((time2 - time1)* (num_iterations - it_nr))\n",
    "    print (\"remaining {:02d}:{:02d}:{:02d}\".format(remaining//3600, remaining//60%60, remaining%60))\n",
    "    if it_nr % 1000 == 0:\n",
    "        with torch.no_grad():\n",
    "            y_fake = torch.randint(0, generator.n_classes, (batchsize,), device=device, dtype=torch.long)\n",
    "            x_fake = generator(batchsize, y=y_fake)\n",
    "\n",
    "            imgs = x_fake.detach().view(8,8,3,64,64).permute(0,3,1,4,2).reshape(8*64,8*64,3)\n",
    "            imgs = imgs - imgs.min()\n",
    "            imgs = imgs / imgs.max()\n",
    "            pyplot.figure(figsize=(10,10))\n",
    "            pyplot.imshow(imgs.cpu().numpy())\n",
    "            pyplot.savefig(f\"sample_{it_nr}.jpg\")\n",
    "    if it_nr % 5000 == 0:\n",
    "        print (\"saving snapshot\")\n",
    "        torch.save([discriminator.state_dict(), generator.state_dict()], f\"snapshot_{it_nr}.pt\")\n",
    "print (\"saving snapshot\")\n",
    "torch.save([discriminator.state_dict(), generator.state_dict()], f\"snapshot_{it_nr}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "[dis_sd, gen_sd] = torch.load('./snapshot_{it_nr}.pt')\n",
    "discriminator.load_state_dict(dis_sd)\n",
    "generator.load_state_dict(gen_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fake = torch.randint(0, generator.n_classes, (batchsize,), device=device, dtype=torch.long)\n",
    "x_fake = generator(batchsize, y=y_fake)\n",
    "\n",
    "imgs = x_fake.detach().view(8,8,3,64,64).permute(0,3,1,4,2).reshape(8*64,8*64,3)\n",
    "imgs = imgs - imgs.min()\n",
    "imgs = imgs / imgs.max()\n",
    "%matplotlib inline\n",
    "pyplot.figure(figsize=(10,10))\n",
    "pyplot.imshow(imgs.cpu().numpy())\n",
    "pyplot.savefig('sample_{it_nr}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
